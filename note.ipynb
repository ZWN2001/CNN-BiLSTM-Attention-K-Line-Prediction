{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K线图预测\n",
    "## 依赖与超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, LSTM, Conv1D, Dropout, Bidirectional, Multiply, BatchNormalization\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE_ATTENTION_VECTOR = False\n",
    "INPUT_DIMS = 4\n",
    "TIME_STEPS = 20\n",
    "lstm_units = 64\n",
    "epoch = 30\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型与使用到的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = inputs\n",
    "    # a = Permute((2, 1))(inputs)\n",
    "    # a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(input_dim, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((1, 2), name='attention_vec')(a)\n",
    "\n",
    "    output_attention_mul = Multiply()([inputs, a_probs])\n",
    "    return output_attention_mul\n",
    "\n",
    "\n",
    "def create_dataset(dataset, look_back):\n",
    "    \"\"\"\n",
    "    对数据进行处理\n",
    "    \"\"\"\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back - 1):\n",
    "        a = dataset[i:(i + look_back), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, :])\n",
    "    TrainX = np.array(dataX)\n",
    "    Train_Y = np.array(dataY)\n",
    "\n",
    "    return TrainX, Train_Y\n",
    "\n",
    "\n",
    "# 多维归一化  返回数据和最大最小值\n",
    "def NormalizeMult(data):\n",
    "    # normalize 用于反归一化\n",
    "    normalize = np.arange(2 * data.shape[1], dtype='float64')\n",
    "\n",
    "    normalize = normalize.reshape(data.shape[1], 2)\n",
    "    for i in range(0, data.shape[1]):\n",
    "        #第i列\n",
    "        list = data[:, i]\n",
    "        listlow, listhigh = np.percentile(list, [0, 100])\n",
    "        # print(i)\n",
    "        normalize[i, 0] = listlow\n",
    "        normalize[i, 1] = listhigh\n",
    "        delta = listhigh - listlow\n",
    "        if delta != 0:\n",
    "            #第j行\n",
    "            for j in range(0, data.shape[0]):\n",
    "                data[j, i] = (data[j, i] - listlow) / delta\n",
    "    return data, normalize\n",
    "\n",
    "\n",
    "# 多维反归一化\n",
    "def FNormalizeMult(data, normalize):\n",
    "    data = np.array(data)\n",
    "    for i in range(0, data.shape[1]):\n",
    "        listlow = normalize[i, 0]\n",
    "        listhigh = normalize[i, 1]\n",
    "        delta = listhigh - listlow\n",
    "        if delta != 0:\n",
    "            #第j行\n",
    "            for j in range(0, data.shape[0]):\n",
    "                data[j, i] = data[j, i] * delta + listlow\n",
    "\n",
    "    return data\n",
    "\n",
    "def mean_squared_error(test_Y, pred_Y):\n",
    "    # 将输入转换为 NumPy 数组以支持数组运算\n",
    "    test_Y = np.array(test_Y)\n",
    "    pred_Y = np.array(pred_Y)\n",
    "\n",
    "    # 计算均方误差\n",
    "    mse = np.mean((test_Y - pred_Y) ** 2)\n",
    "    return mse\n",
    "\n",
    "\n",
    "\n",
    "def attention_model():\n",
    "    inputs = Input(shape=(TIME_STEPS, INPUT_DIMS))\n",
    "\n",
    "    x = Conv1D(filters=64, kernel_size=1, activation='relu')(inputs)  \n",
    "    x = Dropout(dropout)(x)\n",
    "\n",
    "    # lstm_out = Bidirectional(LSTM(lstm_units, activation='relu'), name='bilstm')(x)\n",
    "    # 对于GPU可以使用CuDNNLSTM\n",
    "    lstm_out = Bidirectional(LSTM(lstm_units, return_sequences=True))(x)\n",
    "    lstm_out = Dropout(dropout)(lstm_out)\n",
    "    attention_mul = attention_3d_block(lstm_out)\n",
    "    attention_mul = Flatten()(attention_mul)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(inputs=[inputs], outputs=output)\n",
    "    return model\n",
    "\n",
    "def attention_model_with_norm():\n",
    "    inputs = Input(shape=(TIME_STEPS, INPUT_DIMS))\n",
    "    x = Conv1D(filters=64, kernel_size=1, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)  # Added Batch Normalization\n",
    "    x = Dropout(dropout)(x)\n",
    "    lstm_out = Bidirectional(LSTM(lstm_units, return_sequences=True))(x)\n",
    "    lstm_out = BatchNormalization()(lstm_out)  # Added Batch Normalization\n",
    "    lstm_out = Dropout(dropout)(lstm_out)\n",
    "    attention_mul = attention_3d_block(lstm_out)\n",
    "    attention_mul = Flatten()(attention_mul)\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(inputs=[inputs], outputs=output)\n",
    "    return model\n",
    "\n",
    "def lstm(model_type):\n",
    "    inputs = Input(shape=(TIME_STEPS, INPUT_DIMS))\n",
    "    \n",
    "    if model_type == 1:\n",
    "        # single-layer LSTM\n",
    "        x = LSTM(lstm_units, return_sequences=False)(inputs)\n",
    "    \n",
    "    if model_type == 2:\n",
    "        # multi-layer LSTM\n",
    "        x = LSTM(lstm_units, return_sequences=True)(inputs)\n",
    "        x = LSTM(lstm_units, return_sequences=False)(x)\n",
    "    \n",
    "    if model_type == 3:\n",
    "        # BiLSTM\n",
    "        x = Bidirectional(LSTM(lstm_units, return_sequences=False))(inputs)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=output)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "# data = pd.read_csv(\"./NFLX.csv\")\n",
    "data = pd.read_csv(\"./data.csv\")\n",
    "data = data[['open', 'close', 'high', 'low']]\n",
    "\n",
    "# 归一化\n",
    "data = np.array(data)\n",
    "data, normalize = NormalizeMult(data)\n",
    "close_column = data[:, 1].reshape(len(data), 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过第t+1天开盘、最高、最低预测收盘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, _ = create_dataset(data, TIME_STEPS)\n",
    "_, train_Y = create_dataset(close_column, TIME_STEPS)\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_X.shape, train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = attention_model()\n",
    "model_type = 1\n",
    "m = lstm(model_type)\n",
    "\n",
    "\n",
    "m.summary()\n",
    "m.compile(optimizer='adam', loss='mse')\n",
    "history = m.fit([train_X], train_Y, epochs=epoch, batch_size=64, validation_split=0.1)\n",
    "# m.save(\"./model.h5\")\n",
    "# np.save(\"normalize.npy\", normalize)\n",
    "\n",
    "# 使用测试集进行预测\n",
    "pred_Y = m.predict(test_X)\n",
    "\n",
    "# After predictions\n",
    "pred_Y_denormalized = FNormalizeMult(pred_Y, normalize)\n",
    "\n",
    "# Assuming test_Y needs denormalization as well\n",
    "test_Y_denormalized = FNormalizeMult(test_Y, normalize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#迭代图像\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(epoch)\n",
    "plt.plot(epochs_range, loss, label='Train Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Test Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Train and Val Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制预测值和真实值\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_Y[:100], label='True Values')\n",
    "plt.plot(pred_Y[:100], label='Predicted Values')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制预测值和真实值\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pred_Y_denormalized[:100], label='True Values')\n",
    "plt.plot(test_Y_denormalized[:100], label='Predicted Values')\n",
    "plt.title('Denormalized True vs Predicted Values ')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred - y_true) / y_true)) * 100\n",
    "def up_down_accuracy(y_true, y_pred):\n",
    "    y_var_test=y_true[1:]-y_true[:len(y_true)-1]#实际涨跌\n",
    "    y_var_predict=y_pred[1:]-y_pred[:len(y_pred)-1]#原始涨跌\n",
    "    txt=np.zeros(len(y_var_test))\n",
    "    for i in range(len(y_var_test-1)):#计算数量\n",
    "        txt[i]=np.sign(y_var_test[i])==np.sign(y_var_predict[i])\n",
    "    result=sum(txt)/len(txt)\n",
    "    return result\n",
    "\n",
    "print('测试集上的MAE/MSE/MAPE/涨跌准确率')\n",
    "print(mean_absolute_error(pred_Y, test_Y))\n",
    "print(mean_squared_error(pred_Y, test_Y) )\n",
    "print(mape(pred_Y, test_Y) )\n",
    "print(up_down_accuracy(pred_Y, test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过前t天预测T+1天开盘、收盘、高点、低点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_tomorrow(dataset, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i + look_back), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, :])\n",
    "    TrainX = np.array(dataX)\n",
    "    Train_Y = np.array(dataY)\n",
    "    return TrainX, Train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = create_dataset_tomorrow(data, TIME_STEPS)\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_X.shape, train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_model2():\n",
    "    inputs = Input(shape=(TIME_STEPS, INPUT_DIMS))\n",
    "    x = Conv1D(filters=64, kernel_size=1, activation='relu')(inputs)\n",
    "    x = Dropout(dropout)(x)\n",
    "    lstm_out = Bidirectional(LSTM(lstm_units, return_sequences=True))(x)\n",
    "    lstm_out = Dropout(dropout)(lstm_out)\n",
    "    attention_mul = attention_3d_block(lstm_out)\n",
    "    attention_mul = Flatten()(attention_mul)\n",
    "    output = Dense(4, activation='linear')(attention_mul)  # 修改了输出\n",
    "    model = Model(inputs=[inputs], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = attention_model2()\n",
    "\n",
    "m.summary()\n",
    "m.compile(optimizer='adam', loss='mse')\n",
    "history = m.fit([train_X], train_Y, epochs=epoch, batch_size=64, validation_split=0.1)\n",
    "# m.save(\"./model.h5\")\n",
    "# np.save(\"normalize.npy\", normalize)\n",
    "\n",
    "# 使用测试集进行预测\n",
    "pred_Y = m.predict(test_X)\n",
    "\n",
    "# After predictions\n",
    "pred_Y_denormalized = FNormalizeMult(pred_Y, normalize)\n",
    "\n",
    "# Assuming test_Y needs denormalization as well\n",
    "test_Y_denormalized = FNormalizeMult(test_Y, normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#迭代图像\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(epoch)\n",
    "plt.plot(epochs_range, loss, label='Train Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Test Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Train and Val Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制预测值和真实值\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_Y[:100, 1], label='True Values')\n",
    "plt.plot(pred_Y[:100, 1], label='Predicted Values')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制预测值和真实值\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_Y_denormalized[:100, 1], label='True Values')\n",
    "plt.plot(pred_Y_denormalized[:100, 1], label='Predicted Values')\n",
    "plt.title('Denormalized True vs Predicted Values ')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(test_Y, pred_Y):\n",
    "    # MAE\n",
    "    mae = mean_absolute_error(test_Y, pred_Y)\n",
    "    \n",
    "    # MSE\n",
    "    mse = mean_squared_error(test_Y, pred_Y)\n",
    "    \n",
    "    # # MAPE\n",
    "    # mape = np.mean(np.abs((test_Y - pred_Y) / test_Y)) * 100\n",
    "    \n",
    "    # 涨跌准确率\n",
    "    test_diff = np.diff(test_Y[:, 1])  # 计算真实值的涨跌\n",
    "    pred_diff = np.diff(pred_Y[:, 1])  # 计算预测值的涨跌\n",
    "    test_sign = np.sign(test_diff)  # 获取真实值涨跌的符号\n",
    "    pred_sign = np.sign(pred_diff)  # 获取预测值涨跌的符号\n",
    "    accuracy = np.mean(test_sign == pred_sign) * 100  # 计算涨跌准确率\n",
    "    \n",
    "    return mae, mse, accuracy\n",
    "\n",
    "# 使用示例\n",
    "mae, mse, accuracy = calculate_metrics(test_Y, pred_Y)\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "# print(f\"MAPE: {mape}%\")\n",
    "print(f\"涨跌准确率: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 应用:CSGO饰品价格预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "name = \"CSOB_AK-47 _ 怪兽在B (久经沙场)_悠悠有品_K线图 (1)\"\n",
    "\n",
    "# 读取 Excel 文件\n",
    "excel_file = f'./{name}.xlsx'\n",
    "df = pd.read_excel(excel_file, header=3, engine='openpyxl')\n",
    "\n",
    "# 去掉前3行\n",
    "df = df.iloc[3:]\n",
    "df = df.drop(df.columns[[0, 5]], axis=1)\n",
    "\n",
    "# 修改标题\n",
    "df.columns = ['open', 'close', 'high', 'low']\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "csv_file = f'./{name}.csv'\n",
    "df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_7days(dataset, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back - 7):  # 预测7天后的数据\n",
    "        a = dataset[i:(i + look_back), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back + 6, :])  # 目标是7天后的数据\n",
    "    TrainX = np.array(dataX)\n",
    "    Train_Y = np.array(dataY)\n",
    "    return TrainX, Train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f\"./{name}.csv\")\n",
    "yesterday_prices = data.iloc[-1]\n",
    "data = np.array(data)\n",
    "data, normalize = NormalizeMult(data)\n",
    "# Prepare data\n",
    "train_X, train_Y = create_dataset_7days(data, TIME_STEPS)\n",
    "\n",
    "# 使用时注释掉\n",
    "# train_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = attention_model2()\n",
    "\n",
    "\n",
    "mm.summary()\n",
    "mm.compile(optimizer='adam', loss='mse')\n",
    "mm.fit([train_X], train_Y, epochs=epoch, batch_size=64, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_data = data[-TIME_STEPS:].reshape(1, TIME_STEPS, INPUT_DIMS)\n",
    "# 使用\n",
    "pred_today = mm.predict(today_data)\n",
    "# 测试\n",
    "# pred_today = mm.predict(test_X)\n",
    "\n",
    "pred_Y_denormalized = FNormalizeMult(pred_today, normalize)\n",
    "\n",
    "print(\"Yesterday's Prices:\")\n",
    "print(yesterday_prices)\n",
    "print(\"\\nToday's Prices:\")\n",
    "print('open', 'close', 'high', 'low')\n",
    "print(pred_Y_denormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Y_denormalized = FNormalizeMult(test_Y, normalize)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(test_Y_denormalized[:100, 1], label='True Values')\n",
    "# plt.plot(pred_Y_denormalized[:100, 1], label='Predicted Values')\n",
    "# plt.title('Denormalized True vs Predicted Values ')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Close')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
